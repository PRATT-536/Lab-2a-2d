{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "83708667-4fdc-1563-7b3a-06b6575d2865"
   },
   "source": [
    "\n",
    "\n",
    "# Build Lab 2a Derive Investor Risk Tolerance\n",
    "\n",
    "The goal of Build Lab 2a is derive the risk tolerance, or risk aversion, of an investor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [1. Problem Definition](#0)\n",
    "* [2. Getting Started - Load Libraries and Dataset](#1)\n",
    "    * [2.1. Load Libraries](#1.1)    \n",
    "    * [2.2. Load Dataset](#1.2)\n",
    "* [3. Data Preparation and Feature Selection](#2)\n",
    "    * [3.1. Preparing the predicted variable](#2.1)    \n",
    "    * [3.2. Feature Selection-Limit the Feature Space](#2.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "# 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the supervised regression framework used for this case study, the predicted variable\n",
    "is the “true” risk tolerance of an individual10 and the predictor variables are demo‐\n",
    "graphic, financial and behavioral attributes of an individual\n",
    "\n",
    "For this case study the data used is from survey of Consumer Finances which is conducted by the Federal Reserve\n",
    "Board. The data source is : \n",
    "https://www.federalreserve.gov/econres/scf_2009p.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='1'></a>\n",
    "# 2. Getting Started- Loading the data and python packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Loading the python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5d8fee34-f454-2642-8b06-ed719f0317e1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns\n",
    "import copy \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Libraries for Statistical Models\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#Libraries for Saving the Model\n",
    "from pickle import dump\n",
    "from pickle import load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.2'></a>\n",
    "## 2.2. Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "787e35f7-bf9e-0969-8d13-a54fa87f3519",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataset = pd.read_excel('SCFP2009panel.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Disable the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "## 3. Data Preparation and Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.1'></a>\n",
    "## 3.1. Preparing the predicted variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset from \"Survey of Consumer Finances\" contains the Household's demographics, net worth, financial and non-financial assets for the same demographics in 2007 (pre-crisis) and 2009(post-crisis). \n",
    "\n",
    "We prepare the predicted variable, which is the \"true\" risk tolerance in the following steps. There are different ways of getting the \"true\" risk tolerance. The idea and the purpose of this case study is to come up with an approach to solve the behavioral finance problem using machine learning. \n",
    "\n",
    "The steps to compute the predicted variables are as follows: \n",
    "\n",
    "1) Compute the Risky asset and the riskless assets for all the individuals in the survey data. Risky and riskless assets are defined as follows: \n",
    "* **Risky assets** is investments in mutual funds, stocks, bonds, commodities, and\n",
    "real estate, and an estimate of human capital. \n",
    "* **Risk Free Assets**: checking and savings balances,certificates of deposit, and other cash balances and equivalents.\n",
    "\n",
    "2) We take the ratio of risky assets to total assets of an investor and consider that as a measure of risk tolerance of an investor. From the data of SCF, we have the data of risky and riskless assets for the individuals for 2007 and 2009. We use this data and normalise the risky assets with the stock price of 2007 vs. 2009 to get risk tolerance. \n",
    "\n",
    "* **Risk Tolerance**  just defined as the ratio of Risky Asset to Riskless Assets normalised with the average S&P500 of 2007 vs 2009. \n",
    "Average S&P500 in 2007: 1478\n",
    "Average S&P500 in 2009: 948\n",
    "\n",
    "3) In a lot of literature, an intelligent investor is the one who doesn't change its risk tolerance during the change in the market. So, we consider the investors who change their risk tolerance by less than 10% between 2007 and 2009 as the intelligent investors. Ofcourse this is a qualitative judgement and is subject to change. However, as mentioned before more than being accurate and precise the purpose of theis case study is to demonstrate the usage of the machine learning and provide a machine learning based framework in behavioral finance and portfolio management which can be further leveraged for more detailed analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average SP500 during 2007 and 2009\n",
    "Average_SP500_2007=1478\n",
    "Average_SP500_2009=948\n",
    "\n",
    "#Risk Tolerance 2007\n",
    "dataset['RiskFree07']= dataset['LIQ07'] + dataset['CDS07'] + dataset['SAVBND07'] + dataset['CASHLI07']\n",
    "dataset['Risky07'] = dataset['NMMF07'] + dataset['STOCKS07'] + dataset['BOND07'] \n",
    "dataset['RT07'] = dataset['Risky07']/(dataset['Risky07']+dataset['RiskFree07'])\n",
    "\n",
    "#Risk Tolerance 2009\n",
    "dataset['RiskFree09']= dataset['LIQ09'] + dataset['CDS09'] + dataset['SAVBND09'] + dataset['CASHLI09']\n",
    "dataset['Risky09'] = dataset['NMMF09'] + dataset['STOCKS09'] + dataset['BOND09'] \n",
    "dataset['RT09'] = dataset['Risky09']/(dataset['Risky09']+dataset['RiskFree09'])*\\\n",
    "                (Average_SP500_2009/Average_SP500_2007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = copy.deepcopy(dataset)  \n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compute the percentage change in risk tolerance between 2007 and 2009. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2['PercentageChange'] = np.abs(dataset2['RT09']/dataset2['RT07']-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for the rows with null or nan values and removing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for any null values and removing the null values'''\n",
    "print('Null Values =',dataset2.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows containing NA\n",
    "dataset2=dataset2.dropna(axis=0)\n",
    "\n",
    "dataset2=dataset2[~dataset2.isin([np.nan, np.inf, -np.inf]).any(1)]\n",
    "\n",
    "#Checking for any null values and removing the null values'''\n",
    "print('Null Values =',dataset2.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot the risk tolerance for both 2007 and 2009. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(dataset2['RT07'], hist=True, kde=False, \n",
    "             bins=int(180/5), color = 'blue',\n",
    "             hist_kws={'edgecolor':'black'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph of investor's risk tolerance in 2007 shows that a significant number of individuals had risk tolerance close to one. This means the investments were skewed towards riskier rather than riskless assets. Now we derive and graph risk tolerance for 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(dataset2['RT09'], hist=True, kde=False, \n",
    "             bins=int(180/5), color = 'blue',\n",
    "             hist_kws={'edgecolor':'black'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3 = copy.deepcopy(dataset2)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The behavior of investors reversed after the 2009 crisis and the majority of investment was reallocated to risk free assets. Overall risk tolerance decreased, which is shown by majority of risk tolerance being close to 0 in 2009. \n",
    "\n",
    "Next we select the investors with high risk tolerance. Their investments changed less than 10% between 2007 and 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3 = dataset3[dataset3['PercentageChange']<=.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assign the true risk tolerance as the average risk tolerance of these intelligent investors between 2007 and 2009. This is the predicted variable for this case study. The purpose would be to predict the true risk tolerance of an individuals given the demographic, financial and willingness to take risk related features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3['TrueRiskTolerance'] = (dataset3['RT07'] + dataset3['RT09'])/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now drop labels which might not be needed for the prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3.drop(labels=['RT07', 'RT09'], axis=1, inplace=True)\n",
    "dataset3.drop(labels=['PercentageChange'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.2'></a>\n",
    "## 3.2. Feature Selection-Limit the Feature Space "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.2.2'></a>\n",
    "### 3.2.2.  Features elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to filter the features further we do the following:\n",
    "1. Check the description in the Data Dictionary (https://www.federalreserve.gov/econres/files/codebk2009p.txt, https://www.federalreserve.gov/econresdata/scf/files/fedstables.macro.txt)and only keep the features that are intuitive\n",
    "The description is as follows: \n",
    "\n",
    "\n",
    "* AGE: There are 6 age categories, where 1 represents age less than 35 and 6 represents age more than 75.\n",
    "* EDUC: There are 4 education categories, where 1 represents no high school and 4 represents college degree.\n",
    "* MARRIED: It represents marital status. There are two categories where 1 represents married and 2 represents unmarried. \n",
    "* OCCU: It represents occupation category. 1 represents managerial category and 4 represents unemployed.\n",
    "* KIDS: It represents number of kids. \n",
    "* NWCAT: It represents net worth category. There are 5 categories, where 1 net worth less than 25 percentile and 5 represents net worth more than 90th percentile. \n",
    "* INCCL: It represents income category. There are 5 categories, where 1 income less than 10,000 and 5 represents net worth more than 100,000\n",
    "* RISK: It represents the willingness to take risk on a scale of 1 to 4, where 1 represents highest level of willingness to take risk. \n",
    "\n",
    "2. Keep only the intuitive factors as of 2007 only and remove all the intermediate features and features related to 2009, as the variables of 2007 are the only ones required for predicting the risk tolerance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_list2 = ['AGE07','EDCL07','MARRIED07','KIDS07','OCCAT107','INCOME07','RISK07','NETWORTH07','TrueRiskTolerance'\n",
    "]\n",
    "\n",
    "drop_list2 = [col for col in dataset3.columns if col not in keep_list2]\n",
    "\n",
    "dataset3.drop(labels=drop_list2, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we calculate the correlation between the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation\n",
    "correlation = dataset3.corr()\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.title('Correlation Matrix')\n",
    "sns.heatmap(correlation, vmax=1, square=True,annot=True,cmap='cubehelix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot Matrix\n",
    "from pandas.plotting import scatter_matrix\n",
    "plt.figure(figsize=(15,15))\n",
    "scatter_matrix(dataset3,figsize=(12,12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the correlation chart above, networth and income are positively correlated with the risk tolerance.\n",
    "With more number of kids and marriage the risk tolerance decreases. As the willingness to take risk decreases the risk tolerance decreases. With age there is a positive relationship of the risk tolerance. \n",
    "\n",
    "Relative risk aversion decreases as people age (i.e., the proportion of net wealth invested in risky assets increases as people age) when other variables are held constant. Therefore, risk tolerance increases with age. \n",
    "\n",
    "In closing, the variables, and their relationship with risk tolerance, seem to align with intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'build_lab2a.sav' \n",
    "dump(dataset3, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 206,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
